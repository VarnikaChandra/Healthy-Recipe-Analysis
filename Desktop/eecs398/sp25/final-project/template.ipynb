{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating recipies \n",
    "\n",
    "**Name(s)**: Varnika Chandra\n",
    "\n",
    "**Website Link**: https://varnikachandra.github.io/Recipes_and_Ratings_Analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import seaborn as sns\n",
    "os.makedirs(\"assets\", exist_ok=True)\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# from lec_utils import * # Feel free to uncomment and use this. It'll make your plotly graphs look like ours in lecture!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/RAW_recipes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSome questions that interested me about the dataset include:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mWhat types of recipes tend to have the most calories?\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Load the datasets\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m recipes_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/RAW_recipes.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m ratings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/RAW_interactions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pds/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pds/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/pds/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pds/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/pds/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/RAW_recipes.csv'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Some questions that interested me about the dataset include:\n",
    "What types of recipes tend to have the most calories?\n",
    "What types of recipes tend to have higher average ratings?\n",
    "What is the relationship between the cooking time and average rating of recipes?\n",
    "What is the relationship between nutrition and cooking time?\n",
    "What is the relationship between nutrition and average ratings of recipes? \n",
    "\n",
    "The question I chose to investigate further is: \n",
    "What makes a recipe healthy? \n",
    "\n",
    "'''\n",
    "#Load the datasets\n",
    "recipes_df = pd.read_csv(\"data/RAW_recipes.csv\")\n",
    "ratings_df = pd.read_csv(\"data/RAW_interactions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "#Rename 'id' to 'recipe_id' to merge\n",
    "recipes_df = recipes_df.rename(columns={'id': 'recipe_id'})\n",
    "\n",
    "#Normalize column names to be consistent\n",
    "def normalize_col_names(df):\n",
    "    df.columns=(\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "        .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    )\n",
    "    return df\n",
    "recipes_df = normalize_col_names(recipes_df)\n",
    "ratings_df = normalize_col_names(ratings_df)\n",
    "\n",
    "#Drop duplicate reviews if same user reviewed a recipe twice\n",
    "ratings_df = ratings_df.drop_duplicates(subset=['user_id', 'recipe_id'])\n",
    "\n",
    "#Remove ratings of 0\n",
    "ratings_df = ratings_df[ratings_df['rating'] != 0]\n",
    "\n",
    "#Replace 'minutes'=0 with NaN, then fill with median of reasonable durations (< 48 hours)\n",
    "reasonable_minutes=recipes_df[recipes_df['minutes']<2880]['minutes']\n",
    "median_minutes=reasonable_minutes.median()\n",
    "recipes_df['minutes'] = recipes_df['minutes'].replace(0, np.nan)\n",
    "recipes_df['minutes'] = recipes_df['minutes'].fillna(median_minutes)\n",
    "recipes_df=recipes_df[recipes_df['minutes'] <= 2880]\n",
    "\n",
    "#Fill any missing descriptions with \"NA\"\n",
    "recipes_df['description']=recipes_df['description'].fillna(\"NA\")\n",
    "\n",
    "#Convert 'submitted' column to datetime and extract the year into a new column\n",
    "recipes_df['submitted']=pd.to_datetime(recipes_df['submitted'], errors='coerce')\n",
    "recipes_df['year_submitted']=recipes_df['submitted'].dt.year\n",
    "\n",
    "#Compute average rating and review count per recipe from interactions\n",
    "rating_summary=ratings_df.groupby('recipe_id').agg(\n",
    "    avg_rating=('rating', 'mean'),\n",
    "    num_reviews=('rating', 'count')\n",
    ").reset_index()\n",
    "\n",
    "#Convert stringified lists to actual lists\n",
    "recipes_df['tags']=recipes_df['tags'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
    "\n",
    "#Keywords for healthy recipies\n",
    "health_keywords=['healthy', 'low-fat', 'low sodium', 'anti-inflammatory', 'low calorie', 'gluten-free', 'sugar-free', 'high-protein', 'paleo']\n",
    "\n",
    "#Function to check if any health keyword is in a recipe's tag list\n",
    "def has_health_tag(tags):\n",
    "    return any(kw in tags for kw in health_keywords)\n",
    "    \n",
    "#Create a binary column for whether a recipe is \"health-tagged\"\n",
    "recipes_df['is_health_tagged']=recipes_df['tags'].apply(has_health_tag).astype(int)\n",
    "\n",
    "#Convert string-formatted nutrition list into actual Python lists for all the elements\n",
    "recipes_df['nutrition']=recipes_df['nutrition'].apply(ast.literal_eval)\n",
    "\n",
    "#Define nutrition column names and expand them into separate columns\n",
    "nutrition_cols=['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']\n",
    "nutrition_df=pd.DataFrame(recipes_df['nutrition'].tolist(), columns=nutrition_cols)\n",
    "\n",
    "#Merge nutrition columns back with recipes_df and drop original 'nutrition' column\n",
    "recipes_df=pd.concat([recipes_df.drop(columns=['nutrition']), nutrition_df], axis=1)\n",
    "\n",
    "#Merge recipe-level rating summary into recipes_df using 'recipe_id'\n",
    "recipes_df=recipes_df.merge(rating_summary, on='recipe_id', how='left')\n",
    "\n",
    "#Ensure nutrition columns are numeric and fill any missing values with median\n",
    "recipes_df[nutrition_cols]=recipes_df[nutrition_cols].apply(pd.to_numeric, errors='coerce')\n",
    "recipes_df[nutrition_cols]=recipes_df[nutrition_cols].fillna(recipes_df[nutrition_cols].median())\n",
    "\n",
    "#Create additional numerical features\n",
    "recipes_df['calories_per_ingredient']=recipes_df['calories']/recipes_df['n_ingredients']\n",
    "\n",
    "#If the recipe is considered quick\n",
    "recipes_df['is_quick']=(recipes_df['minutes']<= 30).astype(int)\n",
    "\n",
    "#Popular recipies\n",
    "recipes_df['is_popular']=(recipes_df['num_reviews'] >= 100).astype(int)\n",
    "\n",
    "#Protien to calories ratio\n",
    "recipes_df['protein_per_calorie']=recipes_df['protein']/recipes_df['calories']\n",
    "\n",
    "#Sugar to calories ratio\n",
    "recipes_df['sugar_per_calorie']=recipes_df['sugar']/recipes_df['calories']\n",
    "\n",
    "recipes_df.head(10).to_html(\"preview_table.html\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Univariate Analysis\n",
    "healthy_df=recipes_df[recipes_df['is_health_tagged'] == 1]\n",
    "healthy_df=healthy_df[healthy_df['minutes'] <= 2880]\n",
    "def cap_percentile(df, column, percentile=95):\n",
    "    return np.percentile(df[column], percentile)\n",
    "\n",
    "\n",
    "fig=px.box(recipes_df, y=\"minutes\", title=\"Box Plot of Recipe Preparation Time\")\n",
    "fig.update_yaxes(range=[0, 180])  # Optional zoom\n",
    "fig.show()\n",
    "\n",
    "#Plot: Calories\n",
    "fig=px.box(healthy_df, y='calories', title='Box Plot of Calories in Health-Tagged Recipes')\n",
    "fig.update_yaxes(range=[100, 1800])\n",
    "fig.show()\n",
    "\n",
    "#zoomed in verion\n",
    "fig.update_yaxes(range=[100, 1000])\n",
    "fig.show()\n",
    "\n",
    "#Plot: Sugar\n",
    "fig_sugar=px.box(healthy_df, y='sugar',\n",
    "                         title='Distribution of Sugar (Health-Tagged Recipes)')\n",
    "fig_sugar.update_yaxes(range=[0, 200])\n",
    "fig_sugar.show()\n",
    "\n",
    "#Plot: Protein\n",
    "protein_cap =cap_percentile(healthy_df, 'protein')\n",
    "fig_protein = px.histogram(healthy_df, x='protein', nbins=150,\n",
    "                           title='Distribution of Protein (Health-Tagged Recipes)')\n",
    "fig_protein.update_traces(marker_line_color='white', marker_line_width=1.2)\n",
    "fig_protein.update_layout(xaxis_range=[0, protein_cap])\n",
    "fig_protein.update_layout(\n",
    "    xaxis_title='Protein (grams)',\n",
    "    yaxis_title='Count',\n",
    "    bargap=0.02,\n",
    ")\n",
    "fig_protein.show()\n",
    "fig_protein.write_html(\"assets/protein_dist.html\", include_plotlyjs=\"cdn\")\n",
    "\n",
    "#Plot: Total Fat\n",
    "\n",
    "fig_fat=px.histogram(healthy_df, x='total_fat', nbins=200,\n",
    "                       title='Distribution of Total Fat (Health-Tagged Recipes)')\n",
    "fig_fat.update_traces(marker_line_color='white', marker_line_width=1.5)\n",
    "fig_fat.update_xaxes(range=[0, 150])\n",
    "fig_fat.update_layout(\n",
    "    xaxis_title='Total Fat',\n",
    "    yaxis_title='Count',\n",
    "    bargap=0.05,\n",
    ")\n",
    "fig_fat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bivariate Analysis\n",
    "#Calories vs. Minutes (Scatter)\n",
    "healthy_df=healthy_df[healthy_df['minutes'] <= 2880]\n",
    "fig = px.scatter(\n",
    "    recipes_df,\n",
    "    x='minutes',\n",
    "    y='calories',\n",
    "    title='Calories vs. Preparation Time for All Recipes',\n",
    "    opacity=0.4,\n",
    "    labels={'minutes': 'Prep Time (minutes)', 'calories': 'Calories'},\n",
    "    color_discrete_sequence=['#AB63FA']\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "#healthy v. unhealthy by rating\n",
    "healthy_df=recipes_df[recipes_df['is_health_tagged']==1].copy()\n",
    "unhealthy_df=recipes_df[recipes_df['is_health_tagged']==0].copy()\n",
    "\n",
    "# 2. Add a column to indicate the group\n",
    "healthy_df['group'] = 'Healthy'\n",
    "unhealthy_df['group'] = 'Unhealthy'\n",
    "\n",
    "# 3. Combine the data\n",
    "combined_df=pd.concat([healthy_df, unhealthy_df])\n",
    "\n",
    "# 4. Plot side-by-side box plots\n",
    "fig = px.box(\n",
    "    combined_df,\n",
    "    x='group',\n",
    "    y='avg_rating',\n",
    "    color='group',\n",
    "    title='Average rating: Healthy vs. Unhealthy',\n",
    "    labels={'group': 'Recipe Type', 'Average rating': 'Rating per Recipe'},\n",
    "    color_discrete_map={'Healthy': 'light green', 'Unhealthy': 'pink'}\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"assets/rating_healthy_v_unhealthy.html\", include_plotlyjs=\"cdn\")\n",
    "#fat healthy v unhealthy \n",
    "fig=px.box(\n",
    "    combined_df,\n",
    "    x='group',\n",
    "    y='total_fat',\n",
    "    color='group',\n",
    "    title='Fat Content: Healthy vs. Unhealthy',\n",
    "    labels={'group': 'Recipe Type', 'Fat Content': 'Fat per Recipe'},\n",
    "    color_discrete_map={'Healthy': 'light green', 'Unhealthy': 'pink'}\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.update_yaxes(range=[0, 500])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interesting Aggregates\n",
    "#What are the most common descriptive tags used for recipes labeled as healthy?\n",
    "#Most common tags found in healthy tags seen\n",
    "healthy_tags_df=recipes_df[recipes_df['is_health_tagged'] == 1][['tags']].explode('tags')\n",
    "#Count the frequency of each tag among healthy recipes\n",
    "tag_counts=healthy_tags_df.value_counts().reset_index(name='count')\n",
    "# Get the top 5 most frequent tags\n",
    "top_healthy_tags = tag_counts.nlargest(5, 'count')\n",
    "display(top_healthy_tags)\n",
    "\n",
    "#top ingredients in healthy v unhealthy\n",
    "healthy_ings = (\n",
    "    recipes_df[recipes_df['is_health_tagged'] == 1.0]\n",
    "    .assign(ingredients=lambda df:df['ingredients'].apply(ast.literal_eval))\n",
    "    .explode('ingredients')['ingredients']\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "unhealthy_ings = (\n",
    "    recipes_df[recipes_df['is_health_tagged'] == 0.0]\n",
    "    .assign(ingredients=lambda df: df['ingredients'].apply(ast.literal_eval))\n",
    "    .explode('ingredients')['ingredients']\n",
    "    .value_counts()\n",
    "    .head(30)\n",
    ")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Healthy': healthy_ings,\n",
    "    'Unhealthy': unhealthy_ings\n",
    "})\n",
    "\n",
    "display(comparison_df)\n",
    "#average content of different nutritional values in healthy versus unhealthy \n",
    "nutrition_cols = ['calories', 'total_fat', 'sugar', 'protein']\n",
    "recipes_df.groupby('is_health_tagged')[nutrition_cols].mean()\n",
    "nutrition_cols=['calories', 'total_fat', 'sugar', 'protein']\n",
    "grouped_nutrition=recipes_df.groupby('is_health_tagged')[nutrition_cols].mean().round(2)\n",
    "print(grouped_nutrition.reset_index().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "#Predict whether a recipe is labeled as “healthy” based on its ingredients.\n",
    "'''\n",
    "I aim to predict a recipe's average user rating using the information about its preperation,\n",
    "such as the time required (minutes), the number of steps, and the number of ingredients. \n",
    "Since the response variable is a numeric score on a continuous scale, this is a regression problem. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "\n",
    "features=['calories', 'protein']\n",
    "target='is_health_tagged'\n",
    "X = recipes_df[features]\n",
    "y = recipes_df[target]\n",
    "valid_idx = y.notna()\n",
    "X=X[valid_idx]\n",
    "y=y[valid_idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "numerical_features = ['calories','protein']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 8. Predict and evaluate\n",
    "y_pred = baseline_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'classifier__max_depth': None, 'classifier__n_estimators': 50}\n",
      "F1 Score: 0.05245734657499363\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.98      0.87     13189\n",
      "         1.0       0.26      0.03      0.05      3524\n",
      "\n",
      "    accuracy                           0.78     16713\n",
      "   macro avg       0.52      0.50      0.46     16713\n",
      "weighted avg       0.68      0.78      0.70     16713\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features=['calories_per_ingredient', 'protein_per_calorie', 'sugar_per_calorie', 'saturated_fat']\n",
    "target='is_health_tagged'\n",
    "\n",
    "#Drop rows with missing data in any feature or label\n",
    "df=recipes_df.dropna(subset=features + [target])\n",
    "\n",
    "#Split data\n",
    "X=df[features]\n",
    "y=df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Preprocessing: scale or transform different features\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('standard', StandardScaler(), ['calories_per_ingredient']),\n",
    "    ('quantile', QuantileTransformer(), ['sugar_per_calorie']),\n",
    "    ('pass_through', 'passthrough', ['protein_per_calorie', 'saturated_fat'])\n",
    "])\n",
    "\n",
    "# Pipeline with classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Grid search for hyperparameters\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = grid_search.predict(X_test)\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
